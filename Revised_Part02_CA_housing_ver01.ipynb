{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part02: Survey of machine learning models for CA housing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter I survey a range of machine learning models, including ridge, support vector, random forest, and gradient boosting regression models.  I am interested in finding a \"best\" model for predicting median_house_value.\n",
    "\n",
    "The g03 linear model from Part01 had a comparative rmse score of \\\\$75,471; when predicting only for districts with a median_house_value < 500K, the error score drops to \\\\$55,832.  Most of the ML algorithms surveyed below should be able to beat these scores.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/greg/Documents/stat/github_repos/CA_housing'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline  \n",
    "                    \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training and test sets created in Part01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16482, 16)\n",
      "(4121, 16)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('/home/greg/Documents/stat/Geron_ML/datasets/housing/train_revised_27JUN2021.csv',\n",
    "                    index_col=0)\n",
    "\n",
    "test = pd.read_csv('/home/greg/Documents/stat/Geron_ML/datasets/housing/test_revised_27JUN2021.csv',\n",
    "                   index_col=0)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "      <th>rooms_per_hh</th>\n",
       "      <th>bdrms_per_room</th>\n",
       "      <th>pop_per_hh</th>\n",
       "      <th>HHdens_ln</th>\n",
       "      <th>long_transf</th>\n",
       "      <th>income_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>-122.17</td>\n",
       "      <td>37.74</td>\n",
       "      <td>43.0</td>\n",
       "      <td>818</td>\n",
       "      <td>193</td>\n",
       "      <td>494</td>\n",
       "      <td>179</td>\n",
       "      <td>2.4776</td>\n",
       "      <td>101600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>4.569832</td>\n",
       "      <td>0.235941</td>\n",
       "      <td>2.759777</td>\n",
       "      <td>8.218130</td>\n",
       "      <td>3.460750</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>-121.94</td>\n",
       "      <td>37.93</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3421</td>\n",
       "      <td>427</td>\n",
       "      <td>1341</td>\n",
       "      <td>428</td>\n",
       "      <td>7.5695</td>\n",
       "      <td>320400.0</td>\n",
       "      <td>INLAND</td>\n",
       "      <td>7.992991</td>\n",
       "      <td>0.124817</td>\n",
       "      <td>3.133178</td>\n",
       "      <td>7.176395</td>\n",
       "      <td>3.897225</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8781</th>\n",
       "      <td>-118.32</td>\n",
       "      <td>33.79</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2924</td>\n",
       "      <td>658</td>\n",
       "      <td>1675</td>\n",
       "      <td>602</td>\n",
       "      <td>3.8287</td>\n",
       "      <td>279900.0</td>\n",
       "      <td>OCEAN</td>\n",
       "      <td>4.857143</td>\n",
       "      <td>0.225034</td>\n",
       "      <td>2.782392</td>\n",
       "      <td>8.339524</td>\n",
       "      <td>3.018262</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9392</th>\n",
       "      <td>-122.54</td>\n",
       "      <td>37.90</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2491</td>\n",
       "      <td>460</td>\n",
       "      <td>937</td>\n",
       "      <td>455</td>\n",
       "      <td>4.4375</td>\n",
       "      <td>370000.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>5.474725</td>\n",
       "      <td>0.184665</td>\n",
       "      <td>2.059341</td>\n",
       "      <td>7.156191</td>\n",
       "      <td>3.264623</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10706</th>\n",
       "      <td>-117.72</td>\n",
       "      <td>33.61</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2033</td>\n",
       "      <td>463</td>\n",
       "      <td>618</td>\n",
       "      <td>450</td>\n",
       "      <td>2.5685</td>\n",
       "      <td>80400.0</td>\n",
       "      <td>OCEAN</td>\n",
       "      <td>4.517778</td>\n",
       "      <td>0.227742</td>\n",
       "      <td>1.373333</td>\n",
       "      <td>8.697871</td>\n",
       "      <td>3.422655</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "334      -122.17     37.74                43.0          818             193   \n",
       "1662     -121.94     37.93                16.0         3421             427   \n",
       "8781     -118.32     33.79                35.0         2924             658   \n",
       "9392     -122.54     37.90                48.0         2491             460   \n",
       "10706    -117.72     33.61                26.0         2033             463   \n",
       "\n",
       "       population  households  median_income  median_house_value  \\\n",
       "334           494         179         2.4776            101600.0   \n",
       "1662         1341         428         7.5695            320400.0   \n",
       "8781         1675         602         3.8287            279900.0   \n",
       "9392          937         455         4.4375            370000.0   \n",
       "10706         618         450         2.5685             80400.0   \n",
       "\n",
       "      ocean_proximity  rooms_per_hh  bdrms_per_room  pop_per_hh  HHdens_ln  \\\n",
       "334          NEAR BAY      4.569832        0.235941    2.759777   8.218130   \n",
       "1662           INLAND      7.992991        0.124817    3.133178   7.176395   \n",
       "8781            OCEAN      4.857143        0.225034    2.782392   8.339524   \n",
       "9392         NEAR BAY      5.474725        0.184665    2.059341   7.156191   \n",
       "10706           OCEAN      4.517778        0.227742    1.373333   8.697871   \n",
       "\n",
       "       long_transf  income_cat  \n",
       "334       3.460750           2  \n",
       "1662      3.897225           5  \n",
       "8781      3.018262           3  \n",
       "9392      3.264623           3  \n",
       "10706     3.422655           2  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16482,)\n",
      "(16482, 13)\n"
     ]
    }
   ],
   "source": [
    "# Remove income_cat and longitude.  Longitude has been mapped\n",
    "# to long_transf.\n",
    "\n",
    "y_train = train['median_house_value'].copy()\n",
    "X_train = train[['housing_median_age','total_rooms','total_bedrooms',\n",
    "                 'population','households','median_income',\n",
    "                 'ocean_proximity','rooms_per_hh','bdrms_per_room',\n",
    "                 'pop_per_hh','HHdens_ln','long_transf','latitude']].copy()\n",
    "print(y_train.shape)\n",
    "print(X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.__class__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OCEAN         7338\n",
       "INLAND        5187\n",
       "NEAR OCEAN    2137\n",
       "NEAR BAY      1820\n",
       "Name: ocean_proximity, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall that we removed the 'ISLAND' records since there \n",
    "# were only 5 in the entire 20.64K dataset. \n",
    "pd.value_counts(X_train['ocean_proximity'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4121,)\n",
      "(4121, 13)\n"
     ]
    }
   ],
   "source": [
    "y_test = test['median_house_value'].copy()\n",
    "y_test.name = 'median_house_value'\n",
    "X_test = test[['housing_median_age','total_rooms','total_bedrooms',\n",
    "                 'population','households','median_income',\n",
    "                 'ocean_proximity','rooms_per_hh','bdrms_per_room',\n",
    "                 'pop_per_hh','HHdens_ln','long_transf','latitude']].copy()\n",
    "print(y_test.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      4121.0\n",
       "mean     210578.0\n",
       "std      130124.0\n",
       "min       22500.0\n",
       "25%      118200.0\n",
       "50%      178800.0\n",
       "75%      262300.0\n",
       "max      777151.0\n",
       "Name: median_house_value, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The training set and test data have median house values > 500K.\n",
    "# In other words, we are working with about 4.8% imputed data\n",
    "# for this variable.\n",
    "\n",
    "round(y_test.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of age vs median_house_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1011, 16)\n",
      "Median:  261500.0\n",
      "Mean:    292187\n"
     ]
    }
   ],
   "source": [
    "df_GE52 = train[train.housing_median_age >= 52]\n",
    "print(df_GE52.shape)\n",
    "print(\"Median:  \" + str(df_GE52.median_house_value.describe()['50%']))\n",
    "print(\"Mean:    \" + str(round(df_GE52.median_house_value.describe()['mean'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median:  176500.0\n",
      "Mean:    207439\n"
     ]
    }
   ],
   "source": [
    "df_LT52 = train[train.housing_median_age < 52]\n",
    "print(\"Median:  \" + str(df_LT52.median_house_value.describe()['50%']))\n",
    "print(\"Mean:    \" + str(round(df_LT52.median_house_value.describe()['mean'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# There is some differentiation of median house value by age.\n",
    "# The medians differ by 85K.  The means differ by 85K.\n",
    "\n",
    "plt.hist(round(df_LT52.median_house_value / 1000), bins=100, \n",
    "         density=True, color='lightgrey', label='< 52yrs')\n",
    "plt.hist(round(df_GE52.median_house_value / 1000), bins=100, \n",
    "         density=True, color='cyan', label='>= 52yrs', alpha=0.3)\n",
    "plt.legend();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load some of the functions we will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures, OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income', 'rooms_per_hh', 'bdrms_per_room', 'pop_per_hh', 'HHdens_ln', 'long_transf', 'latitude']\n"
     ]
    }
   ],
   "source": [
    "# Distinguish between the numerical and categorical features.\n",
    "# We will use this distinction in some of the pipelines below.\n",
    "\n",
    "num_attribs = list(X_train.drop([\"ocean_proximity\"], axis=1).columns)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "print(num_attribs)\n",
    "\n",
    "# There are 13 attributes altogether, excluding the response variable.\n",
    "\n",
    "# Population and households have a very high positive correlation.\n",
    "# Both are highly correlated with total_rooms and total_bedrooms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is useful for displaying scores from cross_val_score.\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Mean: \", round(scores.mean(), 0))\n",
    "    print(\"StdDev: \", round(scores.std(), 0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to obtain comparative rmse scores.  For most scores\n",
    "# I average scores from 500 samples of the testset data, each\n",
    "# sample having 1000 records.\n",
    "\n",
    "def get_rmse(seedv, dat):\n",
    "    \n",
    "    # dat needs to also have median_house_value as a column.\n",
    "    n_rcds = 1000\n",
    "    seedv_len = len(seedv)\n",
    "    vout = np.zeros(seedv_len)\n",
    "    \n",
    "    for i, seed in enumerate(seedv):\n",
    "        \n",
    "        df = dat.sample(n=n_rcds, replace=False, random_state=seed, axis=0)\n",
    "        y_df = df[\"median_house_value\"].copy()\n",
    "        df.drop([\"median_house_value\"], inplace=True, axis=1)\n",
    "        test_score = grid.score(df, y_df)\n",
    "        vout[i] = np.power(-test_score, 0.5)\n",
    "    \n",
    "    # print(np.round(vout[:10]))\n",
    "    # print(vout[vout < 50000])\n",
    "    return round(np.mean(vout[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: ML linear models: OLS, ridge, and lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most of the linear models that follow, I use only the 6 predictors used in the g03 model of Part01.  The work done in Part01 shows that we are likely to get better linear models using only median_income, long_transf, latitude, pop_per_hh, housing_median_age, and HHdens_ln.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_6preds = X_train[['median_income','long_transf','latitude',\n",
    "                          'pop_per_hh','HHdens_ln','housing_median_age']].copy()\n",
    "\n",
    "X_test_6preds = X_test[['median_income','long_transf','latitude',\n",
    "                          'pop_per_hh','HHdens_ln','housing_median_age']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  79297.0\n",
      "StdDev:  2650.0\n"
     ]
    }
   ],
   "source": [
    "# A simple regression with the 6 predictors.\n",
    "\n",
    "lin_reg_cv_scores = cross_val_score(LinearRegression(), X_train_6preds, y_train, \n",
    "                                    scoring=\"neg_mean_squared_error\",\n",
    "                                    cv=10, n_jobs=10)\n",
    "\n",
    "lin_reg_scores = np.sqrt(-lin_reg_cv_scores)\n",
    "display_scores(lin_reg_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I apply the scaler AFTER the polynomial transformations.  \n",
    "# The order matters for the scaler that is chosen in the grid\n",
    "# search.  (Typically I apply the scaler first.)\n",
    "\n",
    "pipe = Pipeline([('poly', PolynomialFeatures()), \n",
    "                 ('scaler', MinMaxScaler()),\n",
    "                 ('model', LinearRegression())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A parameter grid for LinearRegression().\n",
    "\n",
    "param_grid = {'poly__degree': [1,2,3], \n",
    "              'scaler': [StandardScaler(), MinMaxScaler(),\n",
    "                         None, RobustScaler()]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'poly__degree': 3, 'scaler': None}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(pipe, param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=10)\n",
    "grid.fit(X_train_6preds, y_train)\n",
    "\n",
    "grid.best_params_\n",
    "# {'poly__degree': 3, 'scaler': None}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 68141\n",
      "Test-set score: 66259\n"
     ]
    }
   ],
   "source": [
    "# Get scores from the best model.\n",
    "\n",
    "best_score = np.power(-grid.best_score_, 0.5)\n",
    "test_score = grid.score(X_test_6preds, y_test)\n",
    "test_score = np.power(-test_score, 0.5)\n",
    "\n",
    "print(\"Best cross-validation score: {:.0f}\".format(best_score))\n",
    "print(\"Test-set score: {:.0f}\".format(test_score))\n",
    "#  Best cross-validation score: 68,141\n",
    "#  Test-set score: 66,259    \n",
    "\n",
    "# These scores are much better than what we saw for the g03 model in Part01.\n",
    "# This model is much more complex though, with 84 terms (g03 has 15 terms).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMMENTS:\n",
    "\n",
    "# In this instance the grid search returns the same values \n",
    "# if we apply the scaler prior to the polynomial transformation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get comparative score for the OLS model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For consistency, I apply a procedure similar to what I used at the end of Part01.  I take 500 1000-record samples from the testset data and compute an rmse score for each.  I then take the average of these 500 scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparative rmse score for ML OLS model:  $61,151\n"
     ]
    }
   ],
   "source": [
    "# The following is a score for all test districts.\n",
    "\n",
    "testdat = X_test_6preds.join(y_test)\n",
    "\n",
    "seed_choices = np.arange(start=1000, stop=21000, dtype=int)\n",
    "np.random.seed(4321)\n",
    "smp = np.random.choice(seed_choices, size=500, replace=False)\n",
    "\n",
    "OLS_rmse = get_rmse(smp, testdat)\n",
    "\n",
    "print(\"Comparative rmse score for ML OLS model:  \" + '$' +\n",
    "      f'{OLS_rmse:,.0f}')\n",
    "\n",
    "# $61,151\n",
    "\n",
    "# For the g03 model of Part01, this score was 75.5K.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparative rmse score for ML OLS model when median house value < 500K:  $57,448\n"
     ]
    }
   ],
   "source": [
    "# The following is a score for districts with a median_house_value < 500K.\n",
    "\n",
    "testdat2 = testdat[testdat.median_house_value < 500000].copy()\n",
    "\n",
    "OLS_rmse = get_rmse(smp, testdat2)\n",
    "\n",
    "print(\"Comparative rmse score for ML OLS model when median house value < 500K:  \" + '$' +\n",
    "      f'{OLS_rmse:,.0f}')\n",
    "\n",
    "# $57,448\n",
    "\n",
    "# For the g03 model in Part01, this score was 55.8K.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3924, 7)\n",
      "(4121, 7)\n"
     ]
    }
   ],
   "source": [
    "# The difference between the 2 testsets is about 200 records.\n",
    "\n",
    "print(testdat2.shape)\n",
    "print(testdat.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score on 500 samples from the test set data is much lower than what we saw with the g03 model of Part01.  g03's score was 75.5K.  The delta is about 14.4K.\n",
    "\n",
    "But if we limit the test districts to those with a median house value < 500K, the g03 model out-performs the ML OLS model by 1.6K.\n",
    "\n",
    "\n",
    "**OLS best score on test set:**  **61,151**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the scaling is done first.\n",
    "\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('poly', PolynomialFeatures()), \n",
    "                 ('model', Ridge())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep track of the computing time.\n",
    "\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time difference of 0.05 minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model__alpha': 0.01, 'poly__degree': 4}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameter grid for Ridge():\n",
    "\n",
    "# Increasing the alpha parameter \"regularizes\" the coefficients \n",
    "# toward zero (L2 norm), which can improve the generalizability\n",
    "# of the model.\n",
    "param_grid = {'poly__degree': [1,2,3,4], \n",
    "              'model__alpha': list((0.01, 0.1, 1.0, 10) + tuple(range(50, 250, 50)))}\n",
    "\n",
    "start_time = datetime.now()\n",
    "grid = GridSearchCV(pipe, param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=10)\n",
    "grid.fit(X_train_6preds, y_train)\n",
    "stop_time = datetime.now()\n",
    "delta = stop_time - start_time\n",
    "timeval = round(delta.seconds/60, 2)\n",
    "print(\"Time difference of \" + str(timeval) + \" minutes\")\n",
    "# Time difference of 0.05 minutes\n",
    "\n",
    "grid.best_params_\n",
    "# {'model__alpha': 0.01, 'poly__degree': 4}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 66522\n",
      "Test-set score: 64453\n"
     ]
    }
   ],
   "source": [
    "# Get scores from the best model.\n",
    "\n",
    "best_score = np.power(-grid.best_score_, 0.5)\n",
    "test_score = grid.score(X_test_6preds, y_test)\n",
    "test_score = np.power(-test_score, 0.5)\n",
    "\n",
    "print(\"Best cross-validation score: {:.0f}\".format(best_score))\n",
    "print(\"Test-set score: {:.0f}\".format(test_score))\n",
    "#  Best cross-validation score: 66.5K\n",
    "#  Test-set score: 64.5K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have the scaler follow the polynomial transformations.\n",
    "\n",
    "pipe = Pipeline([('poly', PolynomialFeatures()),\n",
    "                 ('scaler', MinMaxScaler()),\n",
    "                 ('model', Ridge())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time difference of 0.1 minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model__alpha': 0.01, 'poly__degree': 4, 'scaler': MinMaxScaler()}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "param_grid = {'poly__degree': [1,2,3,4], 'scaler': [StandardScaler(), MinMaxScaler(), \n",
    "                                                    RobustScaler()],\n",
    "              'model__alpha': list((0.01, 0.02, 0.04, 0.06, 0.08, 0.1, 1.0, 10))}\n",
    "\n",
    "start_time = datetime.now()\n",
    "grid = GridSearchCV(pipe, param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=10)\n",
    "grid.fit(X_train_6preds, y_train)\n",
    "stop_time = datetime.now()\n",
    "delta = stop_time - start_time\n",
    "timeval = round(delta.seconds/60, 2)\n",
    "print(\"Time difference of \" + str(timeval) + \" minutes\")\n",
    "# Time difference of 0.1 minutes\n",
    "\n",
    "grid.best_params_\n",
    "# {'model__alpha': 0.01, 'poly__degree': 4, 'scaler': MinMaxScaler()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 66522\n",
      "Test-set score: 64453\n"
     ]
    }
   ],
   "source": [
    "# Get scores from the best model.\n",
    "\n",
    "best_score = np.power(-grid.best_score_, 0.5)\n",
    "test_score = grid.score(X_test_6preds, y_test)\n",
    "test_score = np.power(-test_score, 0.5)\n",
    "\n",
    "print(\"Best cross-validation score: {:.0f}\".format(best_score))\n",
    "print(\"Test-set score: {:.0f}\".format(test_score))\n",
    "#  Best cross-validation score: 66.5K\n",
    "#  Test-set score: 64.4K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('poly', PolynomialFeatures()), \n",
    "                 ('model', Ridge())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time difference of 0.1 minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model__alpha': 0.01, 'poly__degree': 4, 'scaler': MinMaxScaler()}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This repeats what we first did above for Ridge, but the\n",
    "# search grid now extends over different scalers.\n",
    "\n",
    "param_grid = {'poly__degree': [1,2,3,4], 'scaler': [StandardScaler(), MinMaxScaler(), \n",
    "                                                    RobustScaler()],\n",
    "              'model__alpha': [0.01, 0.02, 0.04, 0.06, 0.08, 0.1, 1.0, 10]}\n",
    "\n",
    "start_time = datetime.now()\n",
    "grid = GridSearchCV(pipe, param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=10)\n",
    "grid.fit(X_train_6preds, y_train)\n",
    "stop_time = datetime.now()\n",
    "delta = stop_time - start_time\n",
    "timeval = round(delta.seconds/60, 2)\n",
    "print(\"Time difference of \" + str(timeval) + \" minutes\")\n",
    "# Time difference of 0.1 minutes\n",
    "\n",
    "grid.best_params_\n",
    "# {'model__alpha': 0.01, 'poly__degree': 4, 'scaler': MinMaxScaler()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 66522\n",
      "Test-set score: 64453\n"
     ]
    }
   ],
   "source": [
    "# Get scores from the best model.\n",
    "\n",
    "best_score = np.power(-grid.best_score_, 0.5)\n",
    "test_score = grid.score(X_test_6preds, y_test)\n",
    "test_score = np.power(-test_score, 0.5)\n",
    "\n",
    "print(\"Best cross-validation score: {:.0f}\".format(best_score))\n",
    "print(\"Test-set score: {:.0f}\".format(test_score))\n",
    "#  Best cross-validation score: 66.5K\n",
    "#  Test-set score: 64.5K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get comparative score for the Ridge model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparative rmse score for the Ridge model:  $59,851\n"
     ]
    }
   ],
   "source": [
    "# The following is a score for all test districts.\n",
    "\n",
    "testdat = X_test_6preds.join(y_test)\n",
    "\n",
    "seed_choices = np.arange(start=1000, stop=21000, dtype=int)\n",
    "np.random.seed(4321)\n",
    "smp = np.random.choice(seed_choices, size=500, replace=False)\n",
    "\n",
    "rmse_score = get_rmse(smp, testdat)\n",
    "\n",
    "print(\"Comparative rmse score for the Ridge model:  \" + '$' +\n",
    "      f'{rmse_score:,.0f}')\n",
    "\n",
    "# $59,851\n",
    "\n",
    "# For the g03 model of Part01, this score was 75.5K.\n",
    "\n",
    "# The ML OLS model's score was: $61,151\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparative rmse score for the Ridge model when median house value < 500K:  $55,282\n"
     ]
    }
   ],
   "source": [
    "# The following is a score for districts with a median_house_value < 500K.\n",
    "\n",
    "testdat2 = testdat[testdat.median_house_value < 500000].copy()\n",
    "\n",
    "rmse_score = get_rmse(smp, testdat2)\n",
    "\n",
    "print(\"Comparative rmse score for the Ridge model when median house value < 500K:  \" + '$' +\n",
    "      f'{rmse_score:,.0f}')\n",
    "\n",
    "# $55,282\n",
    "\n",
    "# For the g03 model in Part01, this score was 55.8K.\n",
    "\n",
    "# For the ML OLS model, the score was 57.5K.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments on Ridge model using only the 6 predictors of the g03 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus far, our best predictive model is the ridge regression.\n",
    "\n",
    "\n",
    "**Ridge model *tentative* best score on test set:** **59.9K**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add more predictors to the Ridge model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can improve the ridge model somewhat by adding predictors total_rooms and rooms_per_hh.\n",
    "\n",
    "From what I am seeing, the categorical variable, ocean_proximity, does not help us get a better predictive model.  (I hedge because there are a number of combinations with ocean_proximity that I do not test in what follows.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>rooms_per_hh</th>\n",
       "      <th>bdrms_per_room</th>\n",
       "      <th>pop_per_hh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_rooms</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.926511</td>\n",
       "      <td>0.858527</td>\n",
       "      <td>0.189991</td>\n",
       "      <td>-0.197630</td>\n",
       "      <td>-0.110973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_bedrooms</th>\n",
       "      <td>0.926511</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.874802</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.084066</td>\n",
       "      <td>-0.146140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>0.858527</td>\n",
       "      <td>0.874802</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.074324</td>\n",
       "      <td>0.020928</td>\n",
       "      <td>0.177688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rooms_per_hh</th>\n",
       "      <td>0.189991</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>-0.074324</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.564184</td>\n",
       "      <td>-0.056187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bdrms_per_room</th>\n",
       "      <td>-0.197630</td>\n",
       "      <td>0.084066</td>\n",
       "      <td>0.020928</td>\n",
       "      <td>-0.564184</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pop_per_hh</th>\n",
       "      <td>-0.110973</td>\n",
       "      <td>-0.146140</td>\n",
       "      <td>0.177688</td>\n",
       "      <td>-0.056187</td>\n",
       "      <td>0.007697</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                total_rooms  total_bedrooms  population  rooms_per_hh  \\\n",
       "total_rooms        1.000000        0.926511    0.858527      0.189991   \n",
       "total_bedrooms     0.926511        1.000000    0.874802      0.002857   \n",
       "population         0.858527        0.874802    1.000000     -0.074324   \n",
       "rooms_per_hh       0.189991        0.002857   -0.074324      1.000000   \n",
       "bdrms_per_room    -0.197630        0.084066    0.020928     -0.564184   \n",
       "pop_per_hh        -0.110973       -0.146140    0.177688     -0.056187   \n",
       "\n",
       "                bdrms_per_room  pop_per_hh  \n",
       "total_rooms          -0.197630   -0.110973  \n",
       "total_bedrooms        0.084066   -0.146140  \n",
       "population            0.020928    0.177688  \n",
       "rooms_per_hh         -0.564184   -0.056187  \n",
       "bdrms_per_room        1.000000    0.007697  \n",
       "pop_per_hh            0.007697    1.000000  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In Part01 we saw that households and population are too highly\n",
    "# correlated to include together.  We also see below that \n",
    "# total_bedrooms is highly correlated with population and total_rooms.\n",
    "\n",
    "corr_matrix = train[['total_rooms','total_bedrooms',\n",
    "                     'population', 'rooms_per_hh',\n",
    "                     'bdrms_per_room','pop_per_hh']].corr()\n",
    "corr_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16482, 11)\n"
     ]
    }
   ],
   "source": [
    "# Do not include total_bedrooms or households.\n",
    "\n",
    "X_train_raw = train[['housing_median_age','total_rooms',\n",
    "                         'population','median_income','HHdens_ln',\n",
    "                         'rooms_per_hh','bdrms_per_room','pop_per_hh',\n",
    "                         'ocean_proximity','long_transf','latitude']].copy()\n",
    "print(X_train_raw.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4121, 11)\n"
     ]
    }
   ],
   "source": [
    "X_test_raw = test[['housing_median_age','total_rooms',\n",
    "                         'population','median_income','HHdens_ln',\n",
    "                         'rooms_per_hh','bdrms_per_room','pop_per_hh',\n",
    "                         'ocean_proximity','long_transf','latitude']].copy()\n",
    "print(X_test_raw.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs_raw = list(X_train_raw.drop([\"ocean_proximity\"], axis=1).columns)\n",
    "\n",
    "cat_attribs_raw = ['ocean_proximity']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc = ColumnTransformer([\n",
    "    (\"num\", MinMaxScaler(), num_attribs_raw),\n",
    "    (\"cat\", OneHotEncoder(sparse=False), cat_attribs_raw),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([(\"prep_dat\", preproc),\n",
    "                 ('poly', PolynomialFeatures()), \n",
    "                 ('model', Ridge())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time difference of 0.28 minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model__alpha': 0.03, 'poly__degree': 4}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On my machine Ridge struggles when we test poly__degree=5.    \n",
    "\n",
    "param_grid = {'poly__degree': [3,4],\n",
    "              'model__alpha': [0.01, 0.03, 0.05]}\n",
    "\n",
    "start_time = datetime.now()\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=4)\n",
    "grid.fit(X_train_raw, y_train)\n",
    "stop_time = datetime.now()\n",
    "delta = stop_time - start_time\n",
    "timeval = round(delta.seconds/60, 2)\n",
    "print(\"Time difference of \" + str(timeval) + \" minutes\")\n",
    "# Time difference of 0.28 minutes.\n",
    "\n",
    "grid.best_params_\n",
    "# {'model__alpha': 0.03, 'poly__degree': 4}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 63737\n",
      "Test-set score: 63037\n"
     ]
    }
   ],
   "source": [
    "# Get scores from the best model.\n",
    "\n",
    "best_score = np.power(-grid.best_score_, 0.5)\n",
    "test_score = grid.score(X_test_raw, y_test)\n",
    "test_score = np.power(-test_score, 0.5)\n",
    "\n",
    "print(\"Best cross-validation score: {:.0f}\".format(best_score))\n",
    "print(\"Test-set score: {:.0f}\".format(test_score))\n",
    "#  Best cross-validation score: 63.7K\n",
    "#  Test-set score: 63.0K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get comparative score for the Ridge model that uses more predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparative rmse score for the Ridge model with more predictors:  $63,197\n"
     ]
    }
   ],
   "source": [
    "# The following is a score for all test districts.\n",
    "\n",
    "testdat = test[['housing_median_age','total_rooms',\n",
    "                         'population','median_income','HHdens_ln',\n",
    "                         'rooms_per_hh','bdrms_per_room','pop_per_hh',\n",
    "                         'ocean_proximity','long_transf','latitude',\n",
    "                'median_house_value']].copy()\n",
    "\n",
    "seed_choices = np.arange(start=1000, stop=21000, dtype=int)\n",
    "np.random.seed(4321)\n",
    "smp = np.random.choice(seed_choices, size=500, replace=False)\n",
    "\n",
    "rmse_score = get_rmse(smp, testdat)\n",
    "\n",
    "print(\"Comparative rmse score for the Ridge model with more predictors:  \" + '$' +\n",
    "      f'{rmse_score:,.0f}')\n",
    "\n",
    "# $63,197\n",
    "\n",
    "# For the simpler ridge model this score was 59.85K.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparative rmse score for 2nd Ridge model when median house value < 500K:  $52,511\n"
     ]
    }
   ],
   "source": [
    "# The following is a score for districts with a median_house_value < 500K.\n",
    "\n",
    "testdat2 = testdat[testdat.median_house_value < 500000].copy()\n",
    "\n",
    "rmse_score = get_rmse(smp, testdat2)\n",
    "\n",
    "print(\"Comparative rmse score for 2nd Ridge model when median house value < 500K:  \" + '$' +\n",
    "      f'{rmse_score:,.0f}')\n",
    "\n",
    "# $52,511\n",
    "\n",
    "# For the simpler ridge model this score was 55.3K.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove ocean_proximity and bdrms_per_room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16482, 9)\n"
     ]
    }
   ],
   "source": [
    "X_train_raw = train[['housing_median_age','total_rooms',\n",
    "                         'population','median_income','HHdens_ln',\n",
    "                         'rooms_per_hh','pop_per_hh',\n",
    "                         'long_transf','latitude']].copy()\n",
    "print(X_train_raw.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4121, 9)\n"
     ]
    }
   ],
   "source": [
    "X_test_raw = test[['housing_median_age','total_rooms',\n",
    "                         'population','median_income','HHdens_ln',\n",
    "                         'rooms_per_hh','pop_per_hh',\n",
    "                         'long_transf','latitude']].copy()\n",
    "print(X_test_raw.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('poly', PolynomialFeatures()), \n",
    "                 ('model', Ridge())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time difference of 0.03 minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model__alpha': 0.01, 'poly__degree': 4}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'poly__degree': [3,4],\n",
    "              'model__alpha': [0.01, 0.03, 0.05]}\n",
    "\n",
    "start_time = datetime.now()\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=4)\n",
    "grid.fit(X_train_raw, y_train)\n",
    "stop_time = datetime.now()\n",
    "delta = stop_time - start_time\n",
    "timeval = round(delta.seconds/60, 2)\n",
    "print(\"Time difference of \" + str(timeval) + \" minutes\")\n",
    "# Time difference of 0.03 minutes.\n",
    "\n",
    "grid.best_params_\n",
    "# {'model__alpha': 0.01, 'poly__degree': 4}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 66264\n",
      "Test-set score: 63263\n"
     ]
    }
   ],
   "source": [
    "# Get scores from the best model.\n",
    "\n",
    "best_score = np.power(-grid.best_score_, 0.5)\n",
    "test_score = grid.score(X_test_raw, y_test)\n",
    "test_score = np.power(-test_score, 0.5)\n",
    "\n",
    "print(\"Best cross-validation score: {:.0f}\".format(best_score))\n",
    "print(\"Test-set score: {:.0f}\".format(test_score))\n",
    "#  Best cross-validation score: 66.3K\n",
    "#  Test-set score: 63.3K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get comparative score for this new ridge model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparative rmse score for the 3rd Ridge model:  $59,492\n"
     ]
    }
   ],
   "source": [
    "# The following is a score for all test districts.\n",
    "\n",
    "testdat = test[['housing_median_age','total_rooms',\n",
    "                         'population','median_income','HHdens_ln',\n",
    "                         'rooms_per_hh','pop_per_hh',\n",
    "                         'long_transf','latitude',\n",
    "                'median_house_value']].copy()\n",
    "\n",
    "seed_choices = np.arange(start=1000, stop=21000, dtype=int)\n",
    "np.random.seed(4321)\n",
    "smp = np.random.choice(seed_choices, size=500, replace=False)\n",
    "\n",
    "rmse_score = get_rmse(smp, testdat)\n",
    "\n",
    "print(\"Comparative rmse score for the 3rd Ridge model:  \" + '$' +\n",
    "      f'{rmse_score:,.0f}')\n",
    "\n",
    "# $59,492\n",
    "\n",
    "# For the simpler ridge model this score was 59.85K.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparative rmse score for 3rd Ridge model when median house value < 500K:  $53,843\n"
     ]
    }
   ],
   "source": [
    "# The following is a score for districts with a median_house_value < 500K.\n",
    "\n",
    "testdat2 = testdat[testdat.median_house_value < 500000].copy()\n",
    "\n",
    "rmse_score = get_rmse(smp, testdat2)\n",
    "\n",
    "print(\"Comparative rmse score for 3rd Ridge model when median house value < 500K:  \" + '$' +\n",
    "      f'{rmse_score:,.0f}')\n",
    "\n",
    "# $53,843\n",
    "\n",
    "# For the simpler ridge model this score was 55.3K.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "715"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find out how many terms are in our ridge model.\n",
    "\n",
    "# We can compute this directly.  We have 9 predictors and\n",
    "# the polynomial degree is 4.  (9 + 4)! / 9!4! = 715 terms.\n",
    "\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('poly', PolynomialFeatures(degree= 4)), \n",
    "                 ])\n",
    "X_prepared = pipe.fit_transform(X_train_raw)\n",
    "\n",
    "ridge_reg = Ridge(alpha=0.01).fit(X_prepared, y_train)\n",
    "len(ridge_reg.coef_)\n",
    "# 715\n",
    "\n",
    "# The g03 model from Part01 contains only 15 terms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final comments for the Ridge model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ridge model best score on test set:** **59.5K**\n",
    "\n",
    "The corresponding OLS regression score is 61.2K.  The g03 model had a score of 75.5K.  The Ridge model is more complex than either of these 2 models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso model with 6 predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('poly', PolynomialFeatures()), \n",
    "                 ('model', Lasso(max_iter=10000, tol=0.001))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time difference of 1.77 minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model__alpha': 15, 'poly__degree': 5}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameter grid for Lasso():\n",
    "\n",
    "param_grid = {'poly__degree': [3,4,5], \n",
    "              'model__alpha': [15, 20, 25]}\n",
    "\n",
    "start_time = datetime.now()\n",
    "grid = GridSearchCV(pipe, param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=10)\n",
    "grid.fit(X_train_6preds, y_train)\n",
    "stop_time = datetime.now()\n",
    "delta = stop_time - start_time\n",
    "timeval = round(delta.seconds/60, 2)\n",
    "print(\"Time difference of \" + str(timeval) + \" minutes\")\n",
    "# Time difference of 1.77 minutes\n",
    "\n",
    "grid.best_params_\n",
    "# {'model__alpha': 15, 'poly__degree': 5}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 69305\n",
      "Test-set score: 67282\n"
     ]
    }
   ],
   "source": [
    "# Get scores from the best model.\n",
    "\n",
    "best_score = np.power(-grid.best_score_, 0.5)\n",
    "test_score = grid.score(X_test_6preds, y_test)\n",
    "test_score = np.power(-test_score, 0.5)\n",
    "\n",
    "print(\"Best cross-validation score: {:.0f}\".format(best_score))\n",
    "print(\"Test-set score: {:.0f}\".format(test_score))\n",
    "#  Best cross-validation score: 69.3K\n",
    "#  Test-set score: 67.3K    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get comparative score for the lasso model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparative rmse score for the lasso model:  $64,014\n"
     ]
    }
   ],
   "source": [
    "# The following is a score for all test districts.\n",
    "\n",
    "testdat = X_train_6preds.join(y_test)\n",
    "\n",
    "seed_choices = np.arange(start=1000, stop=21000, dtype=int)\n",
    "np.random.seed(4321)\n",
    "smp = np.random.choice(seed_choices, size=500, replace=False)\n",
    "\n",
    "rmse_score = get_rmse(smp, testdat)\n",
    "\n",
    "print(\"Comparative rmse score for the lasso model:  \" + '$' +\n",
    "      f'{rmse_score:,.0f}')\n",
    "\n",
    "# $64,014\n",
    "\n",
    "# The best ridge model has a score of 59.5K.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparative rmse score for the lasso when median house value < 500K:  $56,892\n"
     ]
    }
   ],
   "source": [
    "# The following is a score for districts with a median_house_value < 500K.\n",
    "\n",
    "testdat2 = testdat[testdat.median_house_value < 500000].copy()\n",
    "\n",
    "rmse_score = get_rmse(smp, testdat2)\n",
    "\n",
    "print(\"Comparative rmse score for the lasso when median house value < 500K:  \" + '$' +\n",
    "      f'{rmse_score:,.0f}')\n",
    "\n",
    "# $56,892\n",
    "\n",
    "# The best ridge model has a score of 53.8K.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments on Lasso model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this dataset and the number of predictors I am working with, and for the basic parameter settings I am using for lasso and ridge, ridge is proving to be much better to work with.  Lasso requires more computing time than ridge, by several orders of magnitude.  This makes experimentation and tuning of the model much more difficult.\n",
    "\n",
    "\n",
    "**Lasso model best score on test set, using 9 predictors:**  **64K**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 Final Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the linear models surveyed above, Ridge has the best score on the testset data.  This holds true even when Ridge is restricted to the 6 predictors of model g03.\n",
    "\n",
    "Ridge has the added virtue of still being relatively fast.  This is not so with lasso (nor with elastic net).  Because lasso does not work well with this dataset, I will not review any elastic net models.  The elastic net models I have looked at struggle in the same way that lasso does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: A Support Vector Machine regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, too, I restrict the models to the 6 predictors used in the g03 model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('scaler', MinMaxScaler()),  \n",
    "                 ('model', SVR(kernel=\"rbf\", C=3500, gamma=0.07))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time difference of 2.6 minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model__C': 200000, 'model__gamma': 0.3, 'scaler': StandardScaler()}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As C increases, the model is less restricted; that is, the model \n",
    "# increases in complexity as C increases.  As gamma decreases, the\n",
    "# model becomes less complex because the Gaussian kernal radius \n",
    "# increases, meaning that more points are considered in each training\n",
    "# sample.\n",
    "\n",
    "# Search for best parameters, Round 1:\n",
    "\n",
    "param_grid = [{'model__C': [100000, 150000, 200000], \n",
    "               'model__gamma': [0.2, 0.3],\n",
    "               'scaler' : [StandardScaler(), RobustScaler(), MinMaxScaler()]\n",
    "               }]\n",
    "\n",
    "start_time = datetime.now()\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=10)\n",
    "grid.fit(X_train_6preds, y_train)\n",
    "stop_time = datetime.now()\n",
    "delta = stop_time - start_time\n",
    "timeval = round(delta.seconds/60, 2)\n",
    "print(\"Time difference of \" + str(timeval) + \" minutes\")\n",
    "# Time difference of 2.6 minutes \n",
    "\n",
    "grid.best_params_\n",
    "# {'model__C': 200000, 'model__gamma': 0.3, 'scaler': StandardScaler()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 62426\n",
      "Test-set score: 60040\n"
     ]
    }
   ],
   "source": [
    "# Get scores from the best model.\n",
    "\n",
    "best_score = np.power(-grid.best_score_, 0.5)\n",
    "test_score = grid.score(X_test_6preds, y_test)\n",
    "test_score = np.power(-test_score, 0.5)\n",
    "\n",
    "print(\"Best cross-validation score: {:.0f}\".format(best_score))\n",
    "print(\"Test-set score: {:.0f}\".format(test_score))\n",
    "#  Best cross-validation score: 62.4K\n",
    "#  Test-set score: 60K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add StandardScaler to the pipe.\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()),  \n",
    "                 ('model', SVR(kernel=\"rbf\"))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time difference of 2.07 minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model__C': 250000, 'model__gamma': 0.4}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search for best parameters, Round 2:\n",
    "\n",
    "param_grid = [{'model__C': [200000, 250000], \n",
    "               'model__gamma': [0.4, 0.5],\n",
    "               }]\n",
    "\n",
    "start_time = datetime.now()\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=10)\n",
    "grid.fit(X_train_6preds, y_train)\n",
    "stop_time = datetime.now()\n",
    "delta = stop_time - start_time\n",
    "timeval = round(delta.seconds/60, 2)\n",
    "print(\"Time difference of \" + str(timeval) + \" minutes\")\n",
    "# Time difference of 2.07 minutes \n",
    "\n",
    "grid.best_params_\n",
    "# {'model__C': 250000, 'model__gamma': 0.4}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 62259\n",
      "Test-set score: 60148\n"
     ]
    }
   ],
   "source": [
    "# Get scores from the best model.\n",
    "\n",
    "best_score = np.power(-grid.best_score_, 0.5)\n",
    "test_score = grid.score(X_test_6preds, y_test)\n",
    "test_score = np.power(-test_score, 0.5)\n",
    "\n",
    "print(\"Best cross-validation score: {:.0f}\".format(best_score))\n",
    "print(\"Test-set score: {:.0f}\".format(test_score))\n",
    "#  Best cross-validation score: 62.3K\n",
    "#  Test-set score: 60.1K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get comparative score for the SVR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparative rmse score for the SVR model:  $57,683\n"
     ]
    }
   ],
   "source": [
    "# The following is a score for all test districts.\n",
    "\n",
    "testdat = X_train_6preds.join(y_test)\n",
    "\n",
    "seed_choices = np.arange(start=1000, stop=21000, dtype=int)\n",
    "np.random.seed(4321)\n",
    "smp = np.random.choice(seed_choices, size=500, replace=False)\n",
    "\n",
    "# The runtime is much longer than any of the previous models.\n",
    "rmse_score = get_rmse(smp, testdat)\n",
    "\n",
    "print(\"Comparative rmse score for the SVR model:  \" + '$' +\n",
    "      f'{rmse_score:,.0f}')\n",
    "\n",
    "# $57,683\n",
    "\n",
    "# The best ridge model has a score of 59.5K.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time difference of 1.6 minutes\n",
      "\n",
      "Comparative rmse score for the SVR model when median house value < 500K:  $49,388\n"
     ]
    }
   ],
   "source": [
    "# The following is a score for districts with a median_house_value < 500K.\n",
    "\n",
    "testdat2 = testdat[testdat.median_house_value < 500000].copy()\n",
    "\n",
    "start_time = datetime.now()\n",
    "rmse_score = get_rmse(smp, testdat2)\n",
    "stop_time = datetime.now()\n",
    "delta = stop_time - start_time\n",
    "timeval = round(delta.seconds/60, 2)\n",
    "print(\"Time difference of \" + str(timeval) + \" minutes\")\n",
    "# Time difference of 1.6 minutes\n",
    "\n",
    "print(\"\")\n",
    "print(\"Comparative rmse score for the SVR model when median house value < 500K:  \" + '$' +\n",
    "      f'{rmse_score:,.0f}')\n",
    "\n",
    "# $49,388\n",
    "\n",
    "# The best ridge model has a score of 53.8K.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final comments on SVM regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With radial basis function for the kernel, the SVR algorithm works quite well.  With only 6 predictors, it is the best performing model thus far in terms of the scores on the testset.  The algorithm requires quite a bit more computing time, however, than all previous models.  \n",
    "\n",
    "Overall, I am impressed with this algorithm.\n",
    "\n",
    "\n",
    "**SVR best score on test set using only 6 predictors:**  **57.7K**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Random forest models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I start by using X_train_9preds.  Previous work has shown that ocean_proximity and pop_per_hh are important predictors for the random forest model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_9preds = X_train[['median_income','long_transf','latitude',\n",
    "                          'pop_per_hh','HHdens_ln','housing_median_age',\n",
    "                          'total_rooms','bdrms_per_room','ocean_proximity']].copy()\n",
    "\n",
    "X_test_9preds = X_test[['median_income','long_transf','latitude',\n",
    "                        'pop_per_hh','HHdens_ln','housing_median_age',\n",
    "                        'total_rooms','bdrms_per_room','ocean_proximity']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = list(X_train_9preds.drop([\"ocean_proximity\"], axis=1).columns)\n",
    "cat_attribs = [\"ocean_proximity\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to convert the levels of ocean_proximity to dummy variables.\n",
    "# The scaling is not required.\n",
    "\n",
    "preproc = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), num_attribs),\n",
    "    (\"cat\", OneHotEncoder(sparse=False), cat_attribs),\n",
    "])\n",
    "\n",
    "pipe = Pipeline([(\"prep_dat\", preproc),\n",
    "                 ('model', RandomForestRegressor(bootstrap=False, random_state=42))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time difference of 8.97 minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model__bootstrap': False,\n",
       " 'model__max_features': 3,\n",
       " 'model__n_estimators': 500}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{'model__bootstrap': [True, False], \n",
    "               'model__n_estimators' : [300, 400, 500],\n",
    "               'model__max_features': [3, 4, 5, 6]\n",
    "               }]\n",
    "\n",
    "start_time = datetime.now()\n",
    "grid = GridSearchCV(pipe, param_grid, cv=7, scoring='neg_mean_squared_error', n_jobs=10)\n",
    "grid.fit(X_train_9preds, y_train)\n",
    "stop_time = datetime.now()\n",
    "delta = stop_time - start_time\n",
    "timeval = round(delta.seconds/60, 2)\n",
    "print(\"Time difference of \" + str(timeval) + \" minutes\")\n",
    "# Time difference of 8.97 minutes \n",
    "\n",
    "grid.best_params_\n",
    "# {'model__bootstrap': False,'model__max_features': 3,'model__n_estimators': 500}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 56105\n",
      "Test-set score: 53188\n"
     ]
    }
   ],
   "source": [
    "# Get scores from the best model.\n",
    "\n",
    "best_score = np.power(-grid.best_score_, 0.5)\n",
    "test_score = grid.score(X_test_9preds, y_test)\n",
    "test_score = np.power(-test_score, 0.5)\n",
    "\n",
    "print(\"Best cross-validation score: {:.0f}\".format(best_score))\n",
    "print(\"Test-set score: {:.0f}\".format(test_score))\n",
    "#  Best cross-validation score: 56.1K\n",
    "#  Test-set score: 53.2K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get comparative score for the random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparative rmse score for the random forest model:  $50,477\n"
     ]
    }
   ],
   "source": [
    "# The following is a score for all test districts.\n",
    "\n",
    "testdat = X_test_9preds.join(y_test)\n",
    "\n",
    "seed_choices = np.arange(start=1000, stop=21000, dtype=int)\n",
    "np.random.seed(4321)\n",
    "smp = np.random.choice(seed_choices, size=500, replace=False)\n",
    "\n",
    "# The runtime is much longer than any of the previous models.\n",
    "rmse_score = get_rmse(smp, testdat)\n",
    "\n",
    "print(\"Comparative rmse score for the random forest model:  \" + '$' +\n",
    "      f'{rmse_score:,.0f}')\n",
    "\n",
    "# $50,477\n",
    "\n",
    "# The previous best model, the SVR, has a score of 57.7K.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time difference of 1.42 minutes\n",
      "\n",
      "Comparative rmse score for the random forest model when median house value < 500K:  $45,267\n"
     ]
    }
   ],
   "source": [
    "# The following is a score for districts with a median_house_value < 500K.\n",
    "\n",
    "testdat2 = testdat[testdat.median_house_value < 500000].copy()\n",
    "\n",
    "start_time = datetime.now()\n",
    "rmse_score = get_rmse(smp, testdat2)\n",
    "stop_time = datetime.now()\n",
    "delta = stop_time - start_time\n",
    "timeval = round(delta.seconds/60, 2)\n",
    "print(\"Time difference of \" + str(timeval) + \" minutes\")\n",
    "# Time difference of 1.42 minutes\n",
    "\n",
    "print(\"\")\n",
    "print(\"Comparative rmse score for the random forest model when median house value < 500K:  \" + '$' +\n",
    "      f'{rmse_score:,.0f}')\n",
    "\n",
    "# $45,267\n",
    "\n",
    "# The previous best model, the SVR, has a score of 49.4K.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importances for the random forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a readable print-out of the feature importances, some preliminary work is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time difference of 0.75 minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model__bootstrap': False,\n",
       " 'model__max_features': 3,\n",
       " 'model__n_estimators': 500}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A restart was required.  So re-establish the grid object.\n",
    "\n",
    "param_grid = [{'model__bootstrap': [False], \n",
    "               'model__n_estimators' : [500],\n",
    "               'model__max_features': [3]\n",
    "               }]\n",
    "\n",
    "start_time = datetime.now()\n",
    "grid = GridSearchCV(pipe, param_grid, cv=7, scoring='neg_mean_squared_error', n_jobs=10)\n",
    "grid.fit(X_train_9preds, y_train)\n",
    "stop_time = datetime.now()\n",
    "delta = stop_time - start_time\n",
    "timeval = round(delta.seconds/60, 2)\n",
    "print(\"Time difference of \" + str(timeval) + \" minutes\")\n",
    "# Time difference of 0.75 minutes \n",
    "\n",
    "grid.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      "Pipeline(steps=[('prep_dat',\n",
      "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
      "                                                  ['median_income',\n",
      "                                                   'long_transf', 'latitude',\n",
      "                                                   'pop_per_hh', 'HHdens_ln',\n",
      "                                                   'housing_median_age',\n",
      "                                                   'total_rooms',\n",
      "                                                   'bdrms_per_room']),\n",
      "                                                 ('cat',\n",
      "                                                  OneHotEncoder(sparse=False),\n",
      "                                                  ['ocean_proximity'])])),\n",
      "                ('model',\n",
      "                 RandomForestRegressor(bootstrap=False, max_features=3,\n",
      "                                       n_estimators=500, random_state=42))])\n"
     ]
    }
   ],
   "source": [
    "print(\"Best estimator:\\n{}\".format(grid.best_estimator_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_dat:\n",
      "ColumnTransformer(transformers=[('num', StandardScaler(),\n",
      "                                 ['median_income', 'long_transf', 'latitude',\n",
      "                                  'pop_per_hh', 'HHdens_ln',\n",
      "                                  'housing_median_age', 'total_rooms',\n",
      "                                  'bdrms_per_room']),\n",
      "                                ('cat', OneHotEncoder(sparse=False),\n",
      "                                 ['ocean_proximity'])])\n"
     ]
    }
   ],
   "source": [
    "best_current_model = grid.best_estimator_.named_steps[\"model\"]\n",
    "\n",
    "feature_importances = best_current_model.feature_importances_.round(4)\n",
    "\n",
    "processed_dat = grid.best_estimator_.named_steps['prep_dat']\n",
    "print(\"processed_dat:\\n{}\".format(processed_dat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['INLAND', 'NEAR BAY', 'NEAR OCEAN', 'OCEAN']\n"
     ]
    }
   ],
   "source": [
    "cat_encoder = processed_dat.named_transformers_['cat']\n",
    "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
    "print(cat_one_hot_attribs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.3153, 'median_income'),\n",
       " (0.1658, 'long_transf'),\n",
       " (0.1212, 'bdrms_per_room'),\n",
       " (0.101, 'pop_per_hh'),\n",
       " (0.0756, 'latitude'),\n",
       " (0.069, 'INLAND'),\n",
       " (0.0505, 'HHdens_ln'),\n",
       " (0.0468, 'housing_median_age'),\n",
       " (0.0343, 'total_rooms'),\n",
       " (0.0102, 'OCEAN'),\n",
       " (0.0052, 'NEAR OCEAN'),\n",
       " (0.0052, 'NEAR BAY')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature importances of our best current random forest model.\n",
    "\n",
    "attributes = num_attribs + cat_one_hot_attribs\n",
    "sorted(zip(feature_importances, attributes), reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMMENTS:\n",
    "\n",
    "# If we construct a model with longitude rather than long_transf, \n",
    "# INLAND is second only to median_income in terms of importance.\n",
    "# So, as expected, the transformation applied to longitude creates\n",
    "# a predictor which negates a great deal of the importance of\n",
    "# ocean_proximity.  \n",
    "\n",
    "# The above output suggests that ocean_proximity is negating some\n",
    "# of the importance of HHdens_ln, the urbanacity metric.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final comments on the random forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest model beats the SVR by \\\\$7,200 and runs a bit faster.  It makes very good use of the bdrms_per_room and pop_per_hh predictors.  Note that in the current model I have neither population nor households.  Both are highly correlated with total_rooms.\n",
    "\n",
    "The score of 50.5K is extraordinary considering that the corresponding score for g03 is 75.5K.  Our ridge model's score is 59.5K.  Ridge is much faster than random forest on this dataset, and g03 is another order of magnitude faster than ridge.  So the better predictions are at a cost.\n",
    "\n",
    "\n",
    "**Random forest best score on the test set:**  **50.5K**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Gradient boosting regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by using X_train_9preds, the same predictors as were used for our random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc = ColumnTransformer([\n",
    "    (\"num\", 'passthrough', num_attribs),\n",
    "    (\"cat\", OneHotEncoder(sparse=False), cat_attribs),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([(\"prep_dat\", preproc),\n",
    "                 (\"model\", GradientBoostingRegressor(random_state=42,\n",
    "                                                     max_depth=3, \n",
    "                                                     n_estimators=1500,\n",
    "                                                     learning_rate=0.12))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for best parameters.\n",
    "\n",
    "param_grid = [{'model__n_estimators': [1200, 1500, 1800],\n",
    "               'model__max_depth': [4, 5],\n",
    "               'model__learning_rate': [0.08, 0.06, 0.04]}]\n",
    "\n",
    "# Using only 5 folds.\n",
    "start_time = datetime.now()\n",
    "print(str(start_time))\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=10)\n",
    "grid.fit(X_train_9preds, y_train)\n",
    "stop_time = datetime.now()\n",
    "delta = stop_time - start_time\n",
    "timeval = round(delta.seconds/60, 2)\n",
    "print(\"Time difference of \" + str(timeval) + \" minutes\")\n",
    "# Time difference of 15.15 minutes \n",
    "\n",
    "grid.best_params_\n",
    "# {'model__learning_rate': 0.04,\n",
    "#  'model__max_depth': 5,\n",
    "#  'model__n_estimators': 1500}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 56808\n",
      "Test-set score: 51882\n"
     ]
    }
   ],
   "source": [
    "# Get scores from the best model.  \n",
    "\n",
    "best_score = np.power(-grid.best_score_, 0.5)\n",
    "test_score = grid.score(X_test_9preds, y_test)\n",
    "test_score = np.power(-test_score, 0.5)\n",
    "\n",
    "print(\"Best cross-validation score: {:.0f}\".format(best_score))\n",
    "print(\"Test-set score: {:.0f}\".format(test_score))\n",
    "# Best cross-validation score: 56.8K\n",
    "# Test-set score: 51.9K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run more cross-folds to get a better measure of the\n",
    "# \"actual\" score and its variability.\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    (\"num\", 'passthrough', num_attribs),\n",
    "    (\"cat\", OneHotEncoder(sparse=False), cat_attribs),\n",
    "])\n",
    "\n",
    "X_train_prepared = ct.fit_transform(X_train_9preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time difference of 4.07 minutes\n",
      "Mean:  55823.0\n",
      "StdDev:  3202.0\n"
     ]
    }
   ],
   "source": [
    "# The parameters used in the model are those which produced the best\n",
    "# cv score for X_train_9preds above.\n",
    "\n",
    "start_time = datetime.now()\n",
    "gbrt_cv_scores = cross_val_score(GradientBoostingRegressor(random_state=42,\n",
    "                                                           max_depth=5, \n",
    "                                                           n_estimators=1500,\n",
    "                                                           learning_rate=0.04),\n",
    "                                 X_train_prepared, y_train, \n",
    "                                 scoring=\"neg_mean_squared_error\",\n",
    "                                 cv=20, n_jobs=10)\n",
    "stop_time = datetime.now()\n",
    "delta = stop_time - start_time\n",
    "timeval = round(delta.seconds/60, 2)\n",
    "print(\"Time difference of \" + str(timeval) + \" minutes\")\n",
    "# Time difference of 4.07 minutes\n",
    "\n",
    "gbrt_scores = np.sqrt(-gbrt_cv_scores)\n",
    "display_scores(gbrt_scores)\n",
    "#  Mean:  55,823.0\n",
    "#  StdDev:  3202.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 56808\n",
      "Test-set score: 51882\n"
     ]
    }
   ],
   "source": [
    "# Get scores from the best model.  \n",
    "\n",
    "best_score = np.power(-grid.best_score_, 0.5)\n",
    "test_score = grid.score(X_test_9preds, y_test)\n",
    "test_score = np.power(-test_score, 0.5)\n",
    "\n",
    "print(\"Best cross-validation score: {:.0f}\".format(best_score))\n",
    "print(\"Test-set score: {:.0f}\".format(test_score))\n",
    "#  Best cross-validation score: 56.8K\n",
    "#  Test-set score: 51.9K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get comparative score for the gradient boosting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparative rmse score for the gradient boosting model:  $48,382\n"
     ]
    }
   ],
   "source": [
    "# The following is a score for all test districts.\n",
    "\n",
    "testdat = X_test_9preds.join(y_test)\n",
    "\n",
    "seed_choices = np.arange(start=1000, stop=21000, dtype=int)\n",
    "np.random.seed(4321)\n",
    "smp = np.random.choice(seed_choices, size=500, replace=False)\n",
    "\n",
    "rmse_score = get_rmse(smp, testdat)\n",
    "\n",
    "print(\"Comparative rmse score for the gradient boosting model:  \" + '$' +\n",
    "      f'{rmse_score:,.0f}')\n",
    "\n",
    "# $48,382\n",
    "\n",
    "# The random forest model has a score of 50.5K.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time difference of 0.17 minutes\n",
      "\n",
      "Comparative rmse score for the gradient boosting model when median house value < 500K:  $46,266\n"
     ]
    }
   ],
   "source": [
    "# The following is a score for districts with a median_house_value < 500K.\n",
    "\n",
    "testdat2 = testdat[testdat.median_house_value < 500000].copy()\n",
    "\n",
    "start_time = datetime.now()\n",
    "rmse_score = get_rmse(smp, testdat2)\n",
    "stop_time = datetime.now()\n",
    "delta = stop_time - start_time\n",
    "timeval = round(delta.seconds/60, 2)\n",
    "print(\"Time difference of \" + str(timeval) + \" minutes\")\n",
    "# Time difference of 0.17 minutes\n",
    "\n",
    "print(\"\")\n",
    "print(\"Comparative rmse score for the gradient boosting model when median house value < 500K:  \" + '$' +\n",
    "      f'{rmse_score:,.0f}')\n",
    "\n",
    "# $46,266\n",
    "\n",
    "# The random forest model has a score of 45.3K.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try xgboost package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try first without ocean_proximity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_8preds = X_train[['median_income','long_transf','latitude',\n",
    "                          'pop_per_hh','HHdens_ln','housing_median_age',\n",
    "                          'total_rooms','bdrms_per_room']].copy()\n",
    "\n",
    "X_test_8preds = X_test[['median_income','long_transf','latitude',\n",
    "                        'pop_per_hh','HHdens_ln','housing_median_age',\n",
    "                        'total_rooms','bdrms_per_room']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing shows that the gamma parameter is not being used here.\n",
    "\n",
    "params = {'booster': 'gbtree', 'max_depth': 6, 'learning_rate': 0.3,\n",
    "          'objective': 'reg:squarederror', 'eval_metric': 'rmse',\n",
    "          'gamma': 1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train_8preds, label= y_train)\n",
    "\n",
    "dtest = xgb.DMatrix(X_test_8preds, label= y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb.cv(params, dtrain, num_boost_round=40, nfold=10,\n",
    "             metrics= ['rmse'], early_stopping_rounds= 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>42308.0</td>\n",
       "      <td>443.0</td>\n",
       "      <td>57942.0</td>\n",
       "      <td>2396.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>42005.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>57962.0</td>\n",
       "      <td>2363.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>41743.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>57908.0</td>\n",
       "      <td>2386.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>41466.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>57892.0</td>\n",
       "      <td>2404.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>41175.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>57881.0</td>\n",
       "      <td>2376.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "35          42308.0           443.0         57942.0         2396.0\n",
       "36          42005.0           391.0         57962.0         2363.0\n",
       "37          41743.0           342.0         57908.0         2386.0\n",
       "38          41466.0           361.0         57892.0         2404.0\n",
       "39          41175.0           480.0         57881.0         2376.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst.tail().round()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>43680.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>57868.0</td>\n",
       "      <td>2195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>43425.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>57854.0</td>\n",
       "      <td>2200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>43193.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>57870.0</td>\n",
       "      <td>2197.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>42956.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>57839.0</td>\n",
       "      <td>2164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>42707.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>57809.0</td>\n",
       "      <td>2114.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "35          43680.0           301.0         57868.0         2195.0\n",
       "36          43425.0           272.0         57854.0         2200.0\n",
       "37          43193.0           283.0         57870.0         2197.0\n",
       "38          42956.0           267.0         57839.0         2164.0\n",
       "39          42707.0           257.0         57809.0         2114.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the parameters.\n",
    "\n",
    "params = {'booster': 'gbtree', 'max_depth': 6, 'learning_rate': 0.25,\n",
    "          'objective': 'reg:squarederror', 'eval_metric': 'rmse'}\n",
    "\n",
    "bst = xgb.cv(params, dtrain, num_boost_round=40, nfold=10,\n",
    "             metrics= ['rmse'], early_stopping_rounds= 3)\n",
    "\n",
    "bst.tail().round()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>45377.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>57346.0</td>\n",
       "      <td>2273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>45126.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>57276.0</td>\n",
       "      <td>2339.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>44920.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>57232.0</td>\n",
       "      <td>2338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>44752.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>57229.0</td>\n",
       "      <td>2339.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>44511.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>57170.0</td>\n",
       "      <td>2313.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "35          45377.0           298.0         57346.0         2273.0\n",
       "36          45126.0           327.0         57276.0         2339.0\n",
       "37          44920.0           361.0         57232.0         2338.0\n",
       "38          44752.0           368.0         57229.0         2339.0\n",
       "39          44511.0           360.0         57170.0         2313.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the parameters.\n",
    "\n",
    "params = {'booster': 'gbtree', 'max_depth': 6, 'learning_rate': 0.20,\n",
    "          'objective': 'reg:squarederror', 'eval_metric': 'rmse'}\n",
    "\n",
    "bst = xgb.cv(params, dtrain, num_boost_round=40, nfold=10,\n",
    "             metrics= ['rmse'], early_stopping_rounds= 3)\n",
    "\n",
    "bst.tail().round()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>48536.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>58370.0</td>\n",
       "      <td>2050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>48319.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>58302.0</td>\n",
       "      <td>2042.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>48059.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>58243.0</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>47823.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>58185.0</td>\n",
       "      <td>1986.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>47639.0</td>\n",
       "      <td>567.0</td>\n",
       "      <td>58139.0</td>\n",
       "      <td>2003.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "35          48536.0           590.0         58370.0         2050.0\n",
       "36          48319.0           576.0         58302.0         2042.0\n",
       "37          48059.0           558.0         58243.0         2015.0\n",
       "38          47823.0           574.0         58185.0         1986.0\n",
       "39          47639.0           567.0         58139.0         2003.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the parameters.\n",
    "\n",
    "params = {'booster': 'gbtree', 'max_depth': 5, 'learning_rate': 0.28,\n",
    "          'objective': 'reg:squarederror', 'eval_metric': 'rmse'}\n",
    "\n",
    "bst = xgb.cv(params, dtrain, num_boost_round=40, nfold=10,\n",
    "             metrics= ['rmse'], early_stopping_rounds= 3)\n",
    "\n",
    "bst.tail().round()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>39423.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>56842.0</td>\n",
       "      <td>2111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>39210.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>56819.0</td>\n",
       "      <td>2094.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38866.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>56778.0</td>\n",
       "      <td>2133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38592.0</td>\n",
       "      <td>369.0</td>\n",
       "      <td>56744.0</td>\n",
       "      <td>2183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>38341.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>56675.0</td>\n",
       "      <td>2148.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "35          39423.0           343.0         56842.0         2111.0\n",
       "36          39210.0           351.0         56819.0         2094.0\n",
       "37          38866.0           349.0         56778.0         2133.0\n",
       "38          38592.0           369.0         56744.0         2183.0\n",
       "39          38341.0           337.0         56675.0         2148.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the parameters.\n",
    "\n",
    "params = {'booster': 'gbtree', 'max_depth': 7, 'learning_rate': 0.20,\n",
    "          'objective': 'reg:squarederror', 'eval_metric': 'rmse'}\n",
    "\n",
    "bst = xgb.cv(params, dtrain, num_boost_round=40, nfold=10,\n",
    "             metrics= ['rmse'], early_stopping_rounds= 3)\n",
    "\n",
    "bst.tail().round()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>33252.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>56509.0</td>\n",
       "      <td>2168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>32964.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>56498.0</td>\n",
       "      <td>2184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>32640.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>56446.0</td>\n",
       "      <td>2202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>32297.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>56399.0</td>\n",
       "      <td>2202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>31973.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>56392.0</td>\n",
       "      <td>2213.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "35          33252.0           396.0         56509.0         2168.0\n",
       "36          32964.0           418.0         56498.0         2184.0\n",
       "37          32640.0           376.0         56446.0         2202.0\n",
       "38          32297.0           395.0         56399.0         2202.0\n",
       "39          31973.0           398.0         56392.0         2213.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the parameters.\n",
    "\n",
    "params = {'booster': 'gbtree', 'max_depth': 8, 'learning_rate': 0.20,\n",
    "          'objective': 'reg:squarederror', 'eval_metric': 'rmse'}\n",
    "\n",
    "bst = xgb.cv(params, dtrain, num_boost_round=40, nfold=10,\n",
    "             metrics= ['rmse'], early_stopping_rounds= 3)\n",
    "\n",
    "bst.tail().round()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36054.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>56535.0</td>\n",
       "      <td>2259.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>35755.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>56506.0</td>\n",
       "      <td>2233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>35538.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>56471.0</td>\n",
       "      <td>2252.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>35249.0</td>\n",
       "      <td>419.0</td>\n",
       "      <td>56425.0</td>\n",
       "      <td>2299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>35024.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>56387.0</td>\n",
       "      <td>2263.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "35          36054.0           273.0         56535.0         2259.0\n",
       "36          35755.0           249.0         56506.0         2233.0\n",
       "37          35538.0           285.0         56471.0         2252.0\n",
       "38          35249.0           419.0         56425.0         2299.0\n",
       "39          35024.0           390.0         56387.0         2263.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the parameters.\n",
    "\n",
    "params = {'booster': 'gbtree', 'max_depth': 8, 'learning_rate': 0.15,\n",
    "          'objective': 'reg:squarederror', 'eval_metric': 'rmse'}\n",
    "\n",
    "bst = xgb.cv(params, dtrain, num_boost_round=40, nfold=10,\n",
    "             metrics= ['rmse'], early_stopping_rounds= 3)\n",
    "\n",
    "bst.tail().round()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>30189.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>56769.0</td>\n",
       "      <td>2107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>29867.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>56739.0</td>\n",
       "      <td>2082.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>29581.0</td>\n",
       "      <td>447.0</td>\n",
       "      <td>56706.0</td>\n",
       "      <td>2098.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>29367.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>56673.0</td>\n",
       "      <td>2077.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>29062.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>56666.0</td>\n",
       "      <td>2038.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "35          30189.0           366.0         56769.0         2107.0\n",
       "36          29867.0           408.0         56739.0         2082.0\n",
       "37          29581.0           447.0         56706.0         2098.0\n",
       "38          29367.0           483.0         56673.0         2077.0\n",
       "39          29062.0           468.0         56666.0         2038.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the parameters.\n",
    "\n",
    "params = {'booster': 'gbtree', 'max_depth': 9, 'learning_rate': 0.15,\n",
    "          'objective': 'reg:squarederror', 'eval_metric': 'rmse'}\n",
    "\n",
    "bst = xgb.cv(params, dtrain, num_boost_round=40, nfold=10,\n",
    "             metrics= ['rmse'], early_stopping_rounds= 3)\n",
    "\n",
    "bst.tail().round()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMMENTS:\n",
    "\n",
    "# Best parameters thus far: max_depth = 8; eta = 0.15.\n",
    "# And from the following cell, it looks like we can use 60 rounds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>31401.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>55963.0</td>\n",
       "      <td>2358.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>31219.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>55929.0</td>\n",
       "      <td>2363.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>31045.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>55927.0</td>\n",
       "      <td>2372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>30886.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>55924.0</td>\n",
       "      <td>2372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>30709.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>55924.0</td>\n",
       "      <td>2371.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "55          31401.0           475.0         55963.0         2358.0\n",
       "56          31219.0           460.0         55929.0         2363.0\n",
       "57          31045.0           476.0         55927.0         2372.0\n",
       "58          30886.0           438.0         55924.0         2372.0\n",
       "59          30709.0           439.0         55924.0         2371.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try with 60 rounds.\n",
    "\n",
    "# Change the parameters.\n",
    "\n",
    "params = {'booster': 'gbtree', 'max_depth': 8, 'learning_rate': 0.15,\n",
    "          'objective': 'reg:squarederror', 'eval_metric': 'rmse'}\n",
    "\n",
    "bst = xgb.cv(params, dtrain, num_boost_round=60, nfold=10,\n",
    "             metrics= ['rmse'], early_stopping_rounds= 3)\n",
    "\n",
    "bst.tail().round()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct xgb model for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {'booster': 'gbtree', 'max_depth': 8, 'learning_rate': 0.15,\n",
    "          'objective': 'reg:squarederror', 'eval_metric': 'rmse'}\n",
    "\n",
    "bst = xgb.train(params, dtrain, num_boost_round=60)\n",
    "\n",
    "preds = bst.predict(dtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52696\n"
     ]
    }
   ],
   "source": [
    "bst_rmse = round(np.power(sum(np.power(preds - np.array(y_test), 2))/len(y_test), 0.5))\n",
    "print(bst_rmse)\n",
    "# 52,696\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb.plot_importance(bst, importance_type= 'weight', xlabel= 'Weight',\n",
    "                    ylabel= None, title=\"Feature importance in terms of weight\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb.plot_importance(bst, importance_type= 'gain', xlabel=\"Gain\", \n",
    "                    show_values= False, ylabel= None,\n",
    "                    title=\"Feature importance in terms of gain\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to obtain comparative rmse scores for our xgb model.\n",
    "\n",
    "def get_xgb_rmse(seedv, dat):\n",
    "    \n",
    "    # dat needs to also have median_house_value as a column.\n",
    "    n_rcds = 1000\n",
    "    seedv_len = len(seedv)\n",
    "    vout = np.zeros(seedv_len)\n",
    "    \n",
    "    for i, seed in enumerate(seedv):\n",
    "        \n",
    "        df = dat.sample(n=n_rcds, replace=False, random_state=seed, axis=0)\n",
    "        y_df = df[\"median_house_value\"].copy()\n",
    "        df.drop([\"median_house_value\"], inplace=True, axis=1)\n",
    "        \n",
    "        df_test = xgb.DMatrix(df, label= y_df)\n",
    "        df_preds = bst.predict(df_test)\n",
    "        vout[i] = round(np.power(sum(np.power(df_preds - np.array(y_df), 2))/len(y_df), 0.5))\n",
    "    \n",
    "    return round(np.mean(vout[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparative rmse score for the xgb model:  $49,090\n"
     ]
    }
   ],
   "source": [
    "# The following is a score for all test districts.\n",
    "\n",
    "testdat = X_test_8preds.join(y_test)\n",
    "\n",
    "seed_choices = np.arange(start=1000, stop=21000, dtype=int)\n",
    "np.random.seed(4321)\n",
    "smp = np.random.choice(seed_choices, size=500, replace=False)\n",
    "\n",
    "rmse_score = get_xgb_rmse(smp, testdat)\n",
    "\n",
    "print(\"Comparative rmse score for the xgb model:  \" + '$' +\n",
    "      f'{rmse_score:,.0f}')\n",
    "\n",
    "# $49,090\n",
    "\n",
    "# The previous gradient boosting model has a score of 48.4K.  But \n",
    "# it makes use of the ocean_proximity predictor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time difference of 0.02 minutes\n",
      "\n",
      "Comparative rmse score for the xgb model when median house value < 500K:  $45,432\n"
     ]
    }
   ],
   "source": [
    "# The following is a score for districts with a median_house_value < 500K.\n",
    "\n",
    "testdat2 = testdat[testdat.median_house_value < 500000].copy()\n",
    "\n",
    "start_time = datetime.now()\n",
    "rmse_score = get_xgb_rmse(smp, testdat2)\n",
    "stop_time = datetime.now()\n",
    "delta = stop_time - start_time\n",
    "timeval = round(delta.seconds/60, 2)\n",
    "print(\"Time difference of \" + str(timeval) + \" minutes\")\n",
    "# Time difference of 0.02 minutes\n",
    "\n",
    "print(\"\")\n",
    "print(\"Comparative rmse score for the xgb model when median house value < 500K:  \" + '$' +\n",
    "      f'{rmse_score:,.0f}')\n",
    "\n",
    "# $45,432\n",
    "\n",
    "# The previous gradient boosting model has a score of 46.3K.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try xgboost with the ocean_proximity predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see in what follows, the xgboost algorithm gives us a better model when we do *not* include ocean_proximity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['median_income', 'long_transf', 'latitude', 'pop_per_hh', 'HHdens_ln',\n",
       "       'housing_median_age', 'total_rooms', 'bdrms_per_room',\n",
       "       'ocean_proximity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_9preds.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INLAND</th>\n",
       "      <th>NEAR BAY</th>\n",
       "      <th>NEAR OCEAN</th>\n",
       "      <th>OCEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8781</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9392</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10706</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       INLAND  NEAR BAY  NEAR OCEAN  OCEAN\n",
       "334         0         1           0      0\n",
       "1662        1         0           0      0\n",
       "8781        0         0           0      1\n",
       "9392        0         1           0      0\n",
       "10706       0         0           0      1"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to pass an ndarray object to xgb.DMatrix.  So the\n",
    "# categorical variable needs to be converted to dummy variables.\n",
    "\n",
    "dumvars_train = pd.get_dummies(X_train_9preds['ocean_proximity'])\n",
    "dumvars_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16482, 12)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_xgb = X_train_9preds.join(dumvars_train)\n",
    "X_train_xgb.drop(['ocean_proximity'], axis=1, inplace=True)\n",
    "X_train_xgb.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4121, 12)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same for the test set.\n",
    "\n",
    "dumvars_test = pd.get_dummies(X_test_9preds['ocean_proximity'])\n",
    "X_test_xgb = X_test_9preds.join(dumvars_test)\n",
    "X_test_xgb.drop(['ocean_proximity'], axis=1, inplace=True)\n",
    "X_test_xgb.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train_xgb, label= y_train)\n",
    "\n",
    "dtest = xgb.DMatrix(X_test_xgb, label= y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>38883.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>56769.0</td>\n",
       "      <td>1839.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>38725.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>56775.0</td>\n",
       "      <td>1854.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>38589.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>56768.0</td>\n",
       "      <td>1872.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>38474.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>56755.0</td>\n",
       "      <td>1864.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>38340.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>56754.0</td>\n",
       "      <td>1892.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "70          38883.0           424.0         56769.0         1839.0\n",
       "71          38725.0           417.0         56775.0         1854.0\n",
       "72          38589.0           410.0         56768.0         1872.0\n",
       "73          38474.0           411.0         56755.0         1864.0\n",
       "74          38340.0           439.0         56754.0         1892.0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'booster': 'gbtree', 'max_depth': 6, 'learning_rate': 0.20,\n",
    "          'objective': 'reg:squarederror', 'eval_metric': 'rmse'}\n",
    "\n",
    "bst = xgb.cv(params, dtrain, num_boost_round=80, nfold=10,\n",
    "             metrics= ['rmse'], early_stopping_rounds= 3)\n",
    "\n",
    "bst.tail().round()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>35815.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>56673.0</td>\n",
       "      <td>2423.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>35619.0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>56637.0</td>\n",
       "      <td>2422.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>35462.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>56631.0</td>\n",
       "      <td>2425.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>35277.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>56627.0</td>\n",
       "      <td>2431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>35077.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>56603.0</td>\n",
       "      <td>2417.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "55          35815.0           459.0         56673.0         2423.0\n",
       "56          35619.0           445.0         56637.0         2422.0\n",
       "57          35462.0           439.0         56631.0         2425.0\n",
       "58          35277.0           485.0         56627.0         2431.0\n",
       "59          35077.0           496.0         56603.0         2417.0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'booster': 'gbtree', 'max_depth': 7, 'learning_rate': 0.18,\n",
    "          'objective': 'reg:squarederror', 'eval_metric': 'rmse'}\n",
    "\n",
    "bst = xgb.cv(params, dtrain, num_boost_round=60, nfold=10,\n",
    "             metrics= ['rmse'], early_stopping_rounds= 3)\n",
    "\n",
    "bst.tail().round()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>33683.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>56431.0</td>\n",
       "      <td>2286.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>33404.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>56416.0</td>\n",
       "      <td>2248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>33177.0</td>\n",
       "      <td>569.0</td>\n",
       "      <td>56398.0</td>\n",
       "      <td>2194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>32921.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>56350.0</td>\n",
       "      <td>2170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>32608.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>56315.0</td>\n",
       "      <td>2190.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "43          33683.0           559.0         56431.0         2286.0\n",
       "44          33404.0           549.0         56416.0         2248.0\n",
       "45          33177.0           569.0         56398.0         2194.0\n",
       "46          32921.0           534.0         56350.0         2170.0\n",
       "47          32608.0           600.0         56315.0         2190.0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'booster': 'gbtree', 'max_depth': 8, 'learning_rate': 0.15,\n",
    "          'objective': 'reg:squarederror', 'eval_metric': 'rmse'}\n",
    "\n",
    "bst = xgb.cv(params, dtrain, num_boost_round=48, nfold=10,\n",
    "             metrics= ['rmse'], early_stopping_rounds= 3)\n",
    "\n",
    "bst.tail().round()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct xgb model for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52770\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = {'booster': 'gbtree', 'max_depth': 8, 'learning_rate': 0.15,\n",
    "          'objective': 'reg:squarederror', 'eval_metric': 'rmse'}\n",
    "\n",
    "bst = xgb.train(params, dtrain, num_boost_round=48)\n",
    "\n",
    "preds = bst.predict(dtest)\n",
    "bst_rmse = round(np.power(sum(np.power(preds - np.array(y_test), 2))/len(y_test), 0.5))\n",
    "print(bst_rmse)\n",
    "# 52,770\n",
    "\n",
    "# The score was a bit lower (52,696) without ocean_proximity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparative rmse score for the xgb model that includes ocean_proximity:  $49,678\n"
     ]
    }
   ],
   "source": [
    "# The following is a score for all test districts.\n",
    "\n",
    "testdat = X_test_xgb.join(y_test)\n",
    "\n",
    "seed_choices = np.arange(start=1000, stop=21000, dtype=int)\n",
    "np.random.seed(4321)\n",
    "smp = np.random.choice(seed_choices, size=500, replace=False)\n",
    "\n",
    "rmse_score = get_xgb_rmse(smp, testdat)\n",
    "\n",
    "print(\"Comparative rmse score for the xgb model that includes ocean_proximity:  \" + '$' +\n",
    "      f'{rmse_score:,.0f}')\n",
    "\n",
    "# $49,678\n",
    "\n",
    "# This score is not as good as the model which does not have ocean_proximity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time difference of 0.02 minutes\n",
      "\n",
      "Comparative rmse score for the xgb model when median house value < 500K:  $46,181\n"
     ]
    }
   ],
   "source": [
    "# The following is a score for districts with a median_house_value < 500K.\n",
    "\n",
    "testdat2 = testdat[testdat.median_house_value < 500000].copy()\n",
    "\n",
    "start_time = datetime.now()\n",
    "rmse_score = get_xgb_rmse(smp, testdat2)\n",
    "stop_time = datetime.now()\n",
    "delta = stop_time - start_time\n",
    "timeval = round(delta.seconds/60, 2)\n",
    "print(\"Time difference of \" + str(timeval) + \" minutes\")\n",
    "# Time difference of 0.02 minutes\n",
    "\n",
    "print(\"\")\n",
    "print(\"Comparative rmse score for the xgb model when median house value < 500K:  \" + '$' +\n",
    "      f'{rmse_score:,.0f}')\n",
    "\n",
    "# $46,181\n",
    "\n",
    "# The previous gradient boosting model has a score of 45.4K.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run better model with more rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train_8preds, label= y_train)\n",
    "\n",
    "dtest = xgb.DMatrix(X_test_8preds, label= y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52366\n"
     ]
    }
   ],
   "source": [
    "params = {'booster': 'gbtree', 'max_depth': 8, 'learning_rate': 0.15,\n",
    "          'objective': 'reg:squarederror', 'eval_metric': 'rmse'}\n",
    "\n",
    "bst = xgb.train(params, dtrain, num_boost_round=80)\n",
    "\n",
    "preds = bst.predict(dtest)\n",
    "bst_rmse = round(np.power(sum(np.power(preds - np.array(y_test), 2))/len(y_test), 0.5))\n",
    "print(bst_rmse)\n",
    "# 52,366\n",
    "\n",
    "# This same model at 60 rounds had a score of 52,696\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparative rmse score for the xgb model with 80 rounds:  $48,548\n"
     ]
    }
   ],
   "source": [
    "# The following is a score for all test districts.\n",
    "\n",
    "testdat = X_test_8preds.join(y_test)\n",
    "\n",
    "seed_choices = np.arange(start=1000, stop=21000, dtype=int)\n",
    "np.random.seed(4321)\n",
    "smp = np.random.choice(seed_choices, size=500, replace=False)\n",
    "\n",
    "rmse_score = get_xgb_rmse(smp, testdat)\n",
    "\n",
    "print(\"Comparative rmse score for the xgb model with 80 rounds:  \" + '$' +\n",
    "      f'{rmse_score:,.0f}')\n",
    "\n",
    "# $48,548\n",
    "\n",
    "# The gradient boosting model that included ocean_proximity has a\n",
    "# score of 48.4K.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time difference of 0.02 minutes\n",
      "\n",
      "Comparative rmse score for the xgb model with 80 rounds when median house value < 500K:  $45,139\n"
     ]
    }
   ],
   "source": [
    "# The following is a score for districts with a median_house_value < 500K.\n",
    "\n",
    "testdat2 = testdat[testdat.median_house_value < 500000].copy()\n",
    "\n",
    "start_time = datetime.now()\n",
    "rmse_score = get_xgb_rmse(smp, testdat2)\n",
    "stop_time = datetime.now()\n",
    "delta = stop_time - start_time\n",
    "timeval = round(delta.seconds/60, 2)\n",
    "print(\"Time difference of \" + str(timeval) + \" minutes\")\n",
    "# Time difference of 0.02 minutes\n",
    "\n",
    "print(\"\")\n",
    "print(\"Comparative rmse score for the xgb model with 80 rounds when median house value < 500K:  \" + '$' +\n",
    "      f'{rmse_score:,.0f}')\n",
    "\n",
    "# $45,139\n",
    "\n",
    "# The gradient boosting model that included ocean_proximity\n",
    "# has a score of 46.3K.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final comments on gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two of the gradient boosting models have near equal performance.  One uses ocean_proximity; the other does not.  I prefer the model with fewer predictors.  Its rmse score is about \\\\$150 more than the gradient boosting model that includes ocean_proximity.  But if we predict only for districts with a median house value < 500K, then the xgb model out-performs its cousin by \\\\$1,200.  Also, the xgboost model is quite a bit faster.\n",
    "\n",
    "There may be other xgboost models that are even better.  I only scratched the surface here.\n",
    "\n",
    "\n",
    "**Gradient boosted regression best score:**  **48.5K**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final comments for Part02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the models surveyed, we obtain the best set of predictions, on average, from an xgboost model.  Recall that the g03 model from Part01 has an rmse score of 75.5K.  By contrast, the xgboost model has a score of 48.5K.  That is almost a 36% reduction in the score.\n",
    "\n",
    "The work involved in producing the g03 model made life significantly easier when surveying the above range of machine learning models, for it provided me with a core set of predictors to focus on.  In the end, I went from using 6 predictors to using 8 of the original 13.  Also, because g03 is a parametric model that can be tuned without relying on cross-validation, I could use it in the Gibbs sampler to impute values for the records with a censored median house value.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
